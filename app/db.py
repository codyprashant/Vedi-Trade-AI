from __future__ import annotations

import os
import json
from typing import Any, Dict, List, Optional, Tuple
import math

import psycopg2
from psycopg2.pool import SimpleConnectionPool
from psycopg2.extras import RealDictCursor, Json, execute_values
from dotenv import load_dotenv
from psycopg2 import sql as psql
from .config import (
    INDICATOR_PARAMS,
    WEIGHTS,
    SIGNAL_THRESHOLD,
    PRIMARY_TIMEFRAME,
    CONFIRMATION_TIMEFRAME,
    TREND_TIMEFRAME,
)


_pool: Optional[SimpleConnectionPool] = None


def get_pool() -> SimpleConnectionPool:
    global _pool
    if _pool is not None:
        return _pool

    # Load env variables from .env (if present)
    load_dotenv()

    user = os.getenv("user") or os.getenv("DB_USER")
    password = os.getenv("password") or os.getenv("DB_PASSWORD")
    host = os.getenv("host") or os.getenv("DB_HOST")
    port = os.getenv("port") or os.getenv("DB_PORT")
    dbname = os.getenv("dbname") or os.getenv("DB_NAME")

    if not all([user, password, host, port, dbname]):
        raise RuntimeError("Database credentials missing. Ensure .env has user, password, host, port, dbname")

    # Enhanced DSN with comprehensive timeout and connection settings
    dsn = (
        f"user={user} password={password} host={host} port={port} dbname={dbname} "
        f"sslmode=require connect_timeout=10 keepalives_idle=600 keepalives_interval=30 keepalives_count=3"
    )
    
    try:
        _pool = SimpleConnectionPool(minconn=2, maxconn=10, dsn=dsn)
        return _pool
    except Exception as e:
        raise RuntimeError(f"Failed to create database connection pool: {e}")


def _get_conn():
    """Get a database connection from the pool with timeout handling."""
    pool = get_pool()
    try:
        conn = pool.getconn()
        if conn is None:
            raise RuntimeError("Failed to get database connection from pool")
        return conn
    except Exception as e:
        raise RuntimeError(f"Database connection error: {e}")


def get_connection():
    """Public accessor for obtaining a raw database connection."""
    return _get_conn()


def _put_conn(conn):
    """Return a database connection to the pool with error handling."""
    if conn is None:
        return
    
    pool = get_pool()
    try:
        # Check if connection is still valid before returning to pool
        if conn.closed == 0:
            pool.putconn(conn)
        else:
            # Connection is closed, don't return to pool
            pass
    except Exception as e:
        # Log error but don't raise to avoid masking original exceptions
        print(f"Warning: Error returning connection to pool: {e}")


def ensure_signals_table() -> None:
    conn = _get_conn()
    try:
        with conn:
            with conn.cursor() as cur:
                cur.execute(
                    """
                    create table if not exists public.signals (
                      id bigint generated by default as identity primary key,
                      timestamp timestamptz not null,
                      symbol text not null,
                      timeframe text not null,
                      side text not null check (side in ('buy','sell')),
                      strength numeric not null,
                      strategy text not null,
                      indicators jsonb not null,
                      contributions jsonb not null,
                      indicator_contributions jsonb,
                      signal_type text,
                      primary_timeframe text,
                      confirmation_timeframe text,
                      trend_timeframe text,
                      h1_trend_direction text check (h1_trend_direction in ('Bullish','Bearish')),
                      h4_trend_direction text check (h4_trend_direction in ('Bullish','Bearish')),
                      alignment_boost numeric,
                      final_signal_strength numeric,
                      entry_price numeric,
                      stop_loss_price numeric,
                      take_profit_price numeric,
                      stop_loss_distance_pips numeric,
                      take_profit_distance_pips numeric,
                      risk_reward_ratio numeric,
                      volatility_state text,
                      is_valid boolean
                    );
                    """
                )
                # Ensure new columns exist
                cur.execute("alter table public.signals add column if not exists indicator_contributions jsonb")
                cur.execute("alter table public.signals add column if not exists signal_type text")
                cur.execute("alter table public.signals add column if not exists primary_timeframe text")
                cur.execute("alter table public.signals add column if not exists confirmation_timeframe text")
                cur.execute("alter table public.signals add column if not exists trend_timeframe text")
                cur.execute("alter table public.signals add column if not exists h1_trend_direction text")
                cur.execute("alter table public.signals add column if not exists h4_trend_direction text")
                cur.execute("alter table public.signals add column if not exists alignment_boost numeric")
                cur.execute("alter table public.signals add column if not exists final_signal_strength numeric")
                cur.execute("alter table public.signals add column if not exists entry_price numeric")
                cur.execute("alter table public.signals add column if not exists stop_loss_price numeric")
                cur.execute("alter table public.signals add column if not exists take_profit_price numeric")
                cur.execute("alter table public.signals add column if not exists stop_loss_distance_pips numeric")
                cur.execute("alter table public.signals add column if not exists take_profit_distance_pips numeric")
                cur.execute("alter table public.signals add column if not exists risk_reward_ratio numeric")
                cur.execute("alter table public.signals add column if not exists volatility_state text")
                cur.execute("alter table public.signals add column if not exists is_valid boolean")
                # Enhanced signal system columns
                cur.execute("alter table public.signals add column if not exists direction_confidence text")
                cur.execute("alter table public.signals add column if not exists direction_reason text")
                # Adaptive threshold and filter metadata columns
                cur.execute("alter table public.signals add column if not exists dynamic_threshold numeric")
                cur.execute("alter table public.signals add column if not exists threshold_factors jsonb")
                cur.execute("alter table public.signals add column if not exists filter_reason text")
                cur.execute("alter table public.signals add column if not exists sanity_check_passed boolean")
                cur.execute("alter table public.signals add column if not exists mtf_confirmation jsonb")
    finally:
        _put_conn(conn)


def ensure_indicator_snapshots_table() -> None:
    """Create table to store periodic indicator analysis snapshots per symbol/timeframe."""
    conn = _get_conn()
    try:
        with conn:
            with conn.cursor() as cur:
                cur.execute(
                    """
                    create table if not exists public.indicator_snapshots (
                      id bigint generated by default as identity primary key,
                      timestamp timestamptz not null,
                      symbol text not null,
                      timeframe text not null,
                      indicators jsonb not null,
                      evaluation jsonb,
                      strategy text,
                      created_at timestamptz default now()
                    );
                    """
                )
                # Idempotent column ensures
                cur.execute("alter table public.indicator_snapshots add column if not exists evaluation jsonb")
                cur.execute("alter table public.indicator_snapshots add column if not exists strategy text")
                cur.execute("alter table public.indicator_snapshots add column if not exists created_at timestamptz default now()")
    finally:
        _put_conn(conn)


def _sanitize_json(value: Any) -> Any:
    """Recursively replace NaN/Inf with None so data is valid JSON for Postgres.

    Handles primitives, dicts, lists/tuples. Leaves other types unchanged.
    """
    try:
        # Floats: convert NaN/Inf to None
        if isinstance(value, float):
            if math.isnan(value) or math.isinf(value):
                return None
            return value
        # Ints/bools/str/None are fine
        if isinstance(value, (int, bool, str)) or value is None:
            return value
        # Dict: sanitize values
        if isinstance(value, dict):
            return {k: _sanitize_json(v) for k, v in value.items()}
        # Lists/Tuples: sanitize items
        if isinstance(value, (list, tuple)):
            return [
                _sanitize_json(v) for v in value
            ]
    except Exception:
        # On any unexpected failure, return None to avoid invalid JSON
        return None
    return value


# Legacy ensure_backtesting_tables function removed - use ensure_new_backtesting_tables instead


# --- Strategy configuration tables and helpers ---

def ensure_strategy_tables() -> None:
    """Create tables for strategies, indicator params, and weights if missing."""
    conn = _get_conn()
    try:
        with conn:
            with conn.cursor() as cur:
                # Strategies master table
                cur.execute(
                    """
                    create table if not exists public.strategies (
                      id bigint generated by default as identity primary key,
                      name text unique not null,
                      description text,
                      is_active boolean default false,
                      primary_timeframe text not null,
                      confirmation_timeframe text not null,
                      trend_timeframe text not null,
                      run_interval_seconds integer not null default 600,
                      signal_threshold numeric not null,
                      created_at timestamptz default now(),
                      updated_at timestamptz default now()
                    );
                    """
                )
                # Indicator configs per strategy
                cur.execute(
                    """
                    create table if not exists public.strategy_indicators (
                      id bigint generated by default as identity primary key,
                      strategy_id bigint not null references public.strategies(id) on delete cascade,
                      indicator_name text not null,
                      params jsonb not null,
                      unique (strategy_id, indicator_name)
                    );
                    """
                )
                # Weights per strategy (stored as jsonb for simplicity)
                cur.execute(
                    """
                    create table if not exists public.strategy_weights (
                      id bigint generated by default as identity primary key,
                      strategy_id bigint not null references public.strategies(id) on delete cascade,
                      weights jsonb not null,
                      unique (strategy_id)
                    );
                    """
                )
    finally:
        _put_conn(conn)


def create_default_gold_strategy_if_missing() -> None:
    """Seed a default 'Gold Strategy' using current static defaults if missing."""
    conn = _get_conn()
    try:
        with conn:
            with conn.cursor() as cur:
                cur.execute("select id from public.strategies where name = %s", ("Gold Strategy",))
                row = cur.fetchone()
                if row:
                    return
                # Insert strategy
                cur.execute(
                    """
                    insert into public.strategies (
                      name, description, is_active, primary_timeframe, confirmation_timeframe, trend_timeframe,
                      run_interval_seconds, signal_threshold
                    ) values (%s,%s,%s,%s,%s,%s,%s,%s) returning id
                    """,
                    (
                        "Gold Strategy",
                        "Default strategy for XAUUSD with technical indicators and MTF validation",
                        True,
                        PRIMARY_TIMEFRAME,
                        CONFIRMATION_TIMEFRAME,
                        TREND_TIMEFRAME,
                        600,
                        50.0,
                    ),
                )
                strategy_id = cur.fetchone()[0]

                # Insert indicator params
                for name, params in INDICATOR_PARAMS.items():
                    cur.execute(
                        """
                        insert into public.strategy_indicators (strategy_id, indicator_name, params)
                        values (%s, %s, %s)
                        """,
                        (strategy_id, name, Json(params)),
                    )

                # Insert weights
                cur.execute(
                    """
                    insert into public.strategy_weights (strategy_id, weights)
                    values (%s, %s)
                    """,
                    (strategy_id, Json(WEIGHTS)),
                )
    finally:
        _put_conn(conn)


def get_strategies() -> List[Dict[str, Any]]:
    conn = _get_conn()
    try:
        with conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                cur.execute(
                    """
                    select id, name, description, is_active, primary_timeframe, confirmation_timeframe, trend_timeframe,
                           run_interval_seconds, signal_threshold, created_at, updated_at
                    from public.strategies order by id asc
                    """
                )
                rows = cur.fetchall()
                return [dict(r) for r in rows]
    finally:
        _put_conn(conn)


def get_strategy_details(strategy_id: int) -> Dict[str, Any]:
    conn = _get_conn()
    try:
        with conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                cur.execute(
                    "select id, name, description, is_active, primary_timeframe, confirmation_timeframe, trend_timeframe, run_interval_seconds, signal_threshold from public.strategies where id = %s",
                    (strategy_id,),
                )
                s = cur.fetchone()
                if not s:
                    raise RuntimeError("Strategy not found")
                cur.execute(
                    "select indicator_name, params from public.strategy_indicators where strategy_id = %s",
                    (strategy_id,),
                )
                inds = cur.fetchall()
                cur.execute(
                    "select weights from public.strategy_weights where strategy_id = %s",
                    (strategy_id,),
                )
                w = cur.fetchone()
                # Build indicator params robustly for both dict and tuple rows
                indicator_params: Dict[str, Any] = {}
                for row in inds:
                    if isinstance(row, dict):
                        name = row.get("indicator_name")
                        params = row.get("params")
                    else:
                        try:
                            name, params = row[0], row[1]
                        except Exception:
                            name, params = None, None
                    if name is not None:
                        indicator_params[name] = params

                # Extract weights robustly
                weights_val: Dict[str, Any] = {}
                if w:
                    if isinstance(w, dict):
                        weights_val = w.get("weights") or {}
                    else:
                        try:
                            weights_val = w[0] if w[0] else {}
                        except Exception:
                            weights_val = {}

                return {
                    **dict(s),
                    "indicator_params": indicator_params,
                    "weights": weights_val,
                }
    finally:
        _put_conn(conn)


def get_active_strategy_config() -> Dict[str, Any]:
    conn = _get_conn()
    try:
        with conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                cur.execute("select id from public.strategies where is_active = true limit 1")
                row = cur.fetchone()
                if not row:
                    # No active strategy; create default and return it
                    create_default_gold_strategy_if_missing()
                    cur.execute("select id from public.strategies where is_active = true limit 1")
                    row = cur.fetchone()
                strategy_id = int(row["id"])
                return get_strategy_details(strategy_id)
    finally:
        _put_conn(conn)


def update_indicator_params(strategy_id: int, indicator_name: str, params: Dict[str, Any]) -> None:
    conn = _get_conn()
    try:
        with conn:
            with conn.cursor() as cur:
                cur.execute(
                    """
                    insert into public.strategy_indicators (strategy_id, indicator_name, params)
                    values (%s,%s,%s)
                    on conflict (strategy_id, indicator_name) do update set params = excluded.params
                    """,
                    (strategy_id, indicator_name, Json(params)),
                )
    finally:
        _put_conn(conn)


def update_strategy_weights(strategy_id: int, weights: Dict[str, Any]) -> None:
    conn = _get_conn()
    try:
        with conn:
            with conn.cursor() as cur:
                cur.execute(
                    """
                    insert into public.strategy_weights (strategy_id, weights)
                    values (%s,%s)
                    on conflict (strategy_id) do update set weights = excluded.weights
                    """,
                    (strategy_id, Json(weights)),
                )
    finally:
        _put_conn(conn)


def update_strategy_schedule(strategy_id: int, run_interval_seconds: int) -> None:
    conn = _get_conn()
    try:
        with conn:
            with conn.cursor() as cur:
                cur.execute(
                    "update public.strategies set run_interval_seconds = %s, updated_at = now() where id = %s",
                    (int(run_interval_seconds), int(strategy_id)),
                )
    finally:
        _put_conn(conn)


def update_strategy_threshold(strategy_id: int, signal_threshold: float) -> None:
    conn = _get_conn()
    try:
        with conn:
            with conn.cursor() as cur:
                cur.execute(
                    "update public.strategies set signal_threshold = %s, updated_at = now() where id = %s",
                    (float(signal_threshold), int(strategy_id)),
                )
    finally:
        _put_conn(conn)


def set_active_strategy(strategy_id: int) -> None:
    conn = _get_conn()
    try:
        with conn:
            with conn.cursor() as cur:
                # Deactivate all, activate one
                cur.execute("update public.strategies set is_active = false")
                cur.execute("update public.strategies set is_active = true where id = %s", (int(strategy_id),))
    finally:
        _put_conn(conn)


def insert_signal(record: Dict[str, Any]) -> None:
    """Insert a single signal record with enhanced error handling and timeout protection."""
    conn = _get_conn()
    try:
        with conn:
            with conn.cursor() as cur:
                # Set statement timeout for this operation
                cur.execute("SET statement_timeout = '30s'")
                
                cur.execute(
                    """
                    insert into public.signals (
                        timestamp, symbol, timeframe, side, strength, strategy, indicators, contributions,
                        indicator_contributions, signal_type,
                        primary_timeframe, confirmation_timeframe, trend_timeframe,
                        h1_trend_direction, h4_trend_direction, alignment_boost, final_signal_strength,
                        entry_price, stop_loss_price, take_profit_price,
                        stop_loss_distance_pips, take_profit_distance_pips,
                        risk_reward_ratio, volatility_state, is_valid,
                        direction_confidence, direction_reason
                    ) values (
                        %s,%s,%s,%s,%s,%s,%s,%s,
                        %s,%s,
                        %s,%s,%s,
                        %s,%s,%s,%s,
                        %s,%s,%s,
                        %s,%s,
                        %s,%s,%s,
                        %s,%s
                    )
                    """,
                    (
                        record["timestamp"],
                        record["symbol"],
                        record["timeframe"],
                        record["side"],
                        record["strength"],
                        record["strategy"],
                        Json(_sanitize_json(record["indicators"])),
                        Json(_sanitize_json(record["contributions"])),
                        Json(_sanitize_json(record.get("indicator_contributions"))),
                        record.get("signal_type"),
                        record.get("primary_timeframe"),
                        record.get("confirmation_timeframe"),
                        record.get("trend_timeframe"),
                        record.get("h1_trend_direction"),
                        record.get("h4_trend_direction"),
                        record.get("alignment_boost"),
                        record.get("final_signal_strength"),
                        record.get("entry_price"),
                        record.get("stop_loss_price"),
                        record.get("take_profit_price"),
                        record.get("stop_loss_distance_pips"),
                        record.get("take_profit_distance_pips"),
                        record.get("risk_reward_ratio"),
                        record.get("volatility_state"),
                        record.get("is_valid"),
                        record.get("direction_confidence"),
                        record.get("direction_reason"),
                    ),
                )
    except psycopg2.OperationalError as e:
        raise RuntimeError(f"Database operational error during signal insert: {e}")
    except psycopg2.IntegrityError as e:
        raise RuntimeError(f"Database integrity error during signal insert: {e}")
    except Exception as e:
        raise RuntimeError(f"Unexpected error during signal insert: {e}")
    finally:
        _put_conn(conn)


def insert_signals_batch(records: List[Dict[str, Any]]) -> None:
    """Insert multiple signal records efficiently using execute_values."""
    if not records:
        return
    
    conn = _get_conn()
    try:
        with conn:
            with conn.cursor() as cur:
                # Set statement timeout for batch operation
                cur.execute("SET statement_timeout = '60s'")
                
                # Prepare the insert query
                insert_query = """
                    insert into public.signals (
                        timestamp, symbol, timeframe, side, strength, strategy, indicators, contributions,
                        indicator_contributions, signal_type,
                        primary_timeframe, confirmation_timeframe, trend_timeframe,
                        h1_trend_direction, h4_trend_direction, alignment_boost, final_signal_strength,
                        entry_price, stop_loss_price, take_profit_price,
                        stop_loss_distance_pips, take_profit_distance_pips,
                        risk_reward_ratio, volatility_state, is_valid,
                        direction_confidence, direction_reason
                    ) values %s
                """
                
                # Prepare values for batch insert
                values = []
                for record in records:
                    values.append((
                        record["timestamp"],
                        record["symbol"],
                        record["timeframe"],
                        record["side"],
                        record["strength"],
                        record["strategy"],
                        Json(_sanitize_json(record["indicators"])),
                        Json(_sanitize_json(record["contributions"])),
                        Json(_sanitize_json(record.get("indicator_contributions"))),
                        record.get("signal_type"),
                        record.get("primary_timeframe"),
                        record.get("confirmation_timeframe"),
                        record.get("trend_timeframe"),
                        record.get("h1_trend_direction"),
                        record.get("h4_trend_direction"),
                        record.get("alignment_boost"),
                        record.get("final_signal_strength"),
                        record.get("entry_price"),
                        record.get("stop_loss_price"),
                        record.get("take_profit_price"),
                        record.get("stop_loss_distance_pips"),
                        record.get("take_profit_distance_pips"),
                        record.get("risk_reward_ratio"),
                        record.get("volatility_state"),
                        record.get("is_valid"),
                        record.get("direction_confidence"),
                        record.get("direction_reason"),
                    ))
                
                # Use execute_values for efficient batch insert
                execute_values(cur, insert_query, values, page_size=100)
                
    except psycopg2.OperationalError as e:
        raise RuntimeError(f"Database operational error during batch signal insert: {e}")
    except psycopg2.IntegrityError as e:
        raise RuntimeError(f"Database integrity error during batch signal insert: {e}")
    except Exception as e:
        raise RuntimeError(f"Unexpected error during batch signal insert: {e}")
    finally:
        _put_conn(conn)


def insert_indicator_snapshot(record: Dict[str, Any]) -> None:
    """Insert a single indicator analysis snapshot."""
    conn = _get_conn()
    try:
        with conn:
            with conn.cursor() as cur:
                cur.execute(
                    """
                    insert into public.indicator_snapshots (
                        timestamp, symbol, timeframe, indicators, evaluation, strategy
                    ) values (%s,%s,%s,%s,%s,%s)
                    """,
                    (
                        record["timestamp"],
                        record["symbol"],
                        record["timeframe"],
                        Json(_sanitize_json(record["indicators"])),
                        Json(_sanitize_json(record.get("evaluation"))),
                        record.get("strategy"),
                    ),
                )
    finally:
        _put_conn(conn)


def fetch_latest_indicator_snapshots(symbols: list[str] | None = None) -> list[dict[str, Any]]:
    """Return the latest snapshot per symbol; optionally filter by provided symbols."""
    conn = _get_conn()
    try:
        with conn:
            with conn.cursor() as cur:
                if symbols:
                    cur.execute(
                        """
                        select distinct on (symbol)
                          symbol, timestamp, timeframe, indicators, evaluation, strategy
                        from public.indicator_snapshots
                        where symbol = any(%s)
                        order by symbol, timestamp desc
                        """,
                        (symbols,),
                    )
                else:
                    cur.execute(
                        """
                        select distinct on (symbol)
                          symbol, timestamp, timeframe, indicators, evaluation, strategy
                        from public.indicator_snapshots
                        order by symbol, timestamp desc
                        """,
                    )
                rows = cur.fetchall()
                out = []
                for r in rows:
                    out.append(
                        {
                            "symbol": r[0],
                            "timestamp": r[1],
                            "timeframe": r[2],
                            "indicators": r[3],
                            "evaluation": r[4],
                            "strategy": r[5],
                        }
                    )
                return out
    finally:
        _put_conn(conn)


def fetch_recent_signals(limit: int = 20) -> List[Dict[str, Any]]:
    conn = _get_conn()
    try:
        with conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                cur.execute(
                    "select * from public.signals order by timestamp desc limit %s",
                    (limit,),
                )
                rows = cur.fetchall()
                return [dict(row) for row in rows]
    finally:
        _put_conn(conn)


def fetch_indicator_contributions(signal_id: int) -> Optional[Any]:
    """Fetch indicator contributions JSON for a given signal id."""

    conn = _get_conn()
    try:
        with conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                cur.execute(
                    """
                    SELECT indicator_contributions
                    FROM public.signals
                    WHERE id = %s
                    """,
                    (signal_id,),
                )
                row = cur.fetchone()
                if not row:
                    return None
                return row.get("indicator_contributions")
    finally:
        _put_conn(conn)


def ensure_new_backtesting_tables() -> None:
    """Create the new unified backtesting tables for the enhanced engine."""
    conn = _get_conn()
    try:
        with conn:
            with conn.cursor() as cur:
                # Main backtests table
                cur.execute("""
                    CREATE TABLE IF NOT EXISTS public.backtests (
                        id SERIAL PRIMARY KEY,
                        strategy_id INT NOT NULL,
                        symbol TEXT NOT NULL,
                        timeframe TEXT NOT NULL,
                        start_date TIMESTAMP NOT NULL,
                        end_date TIMESTAMP NOT NULL,
                        investment FLOAT NOT NULL DEFAULT 10000,
                        total_return_pct FLOAT NOT NULL DEFAULT 0,
                        efficiency_pct FLOAT NOT NULL DEFAULT 0,
                        created_at TIMESTAMP DEFAULT NOW()
                    );
                """)
                
                # Backtest signals table
                cur.execute("""
                    CREATE TABLE IF NOT EXISTS public.backtest_signals (
                        id SERIAL PRIMARY KEY,
                        backtest_id INT NOT NULL REFERENCES public.backtests(id) ON DELETE CASCADE,
                        signal_time TIMESTAMP NOT NULL,
                        direction TEXT NOT NULL CHECK (direction IN ('buy', 'sell')),
                        entry_price FLOAT NOT NULL,
                        exit_price FLOAT,
                        profit_pct FLOAT NOT NULL DEFAULT 0,
                        result TEXT NOT NULL CHECK (result IN ('profit', 'loss', 'open')),
                        confidence FLOAT DEFAULT 0.5,
                        reason TEXT,
                        created_at TIMESTAMP DEFAULT NOW()
                    );
                """)
                
                # Create indexes for better query performance
                cur.execute("""
                    CREATE INDEX IF NOT EXISTS idx_backtests_symbol_timeframe 
                    ON public.backtests(symbol, timeframe);
                """)
                
                cur.execute("""
                    CREATE INDEX IF NOT EXISTS idx_backtests_created_at 
                    ON public.backtests(created_at);
                """)
                
                cur.execute("""
                    CREATE INDEX IF NOT EXISTS idx_backtest_signals_backtest_id 
                    ON public.backtest_signals(backtest_id);
                """)
                
                cur.execute("""
                    CREATE INDEX IF NOT EXISTS idx_backtest_signals_result 
                    ON public.backtest_signals(result);
                """)
                
    finally:
        _put_conn(conn)


def fetch_backtest_summary(backtest_id: int) -> Optional[Dict[str, Any]]:
    """Fetch backtest summary by ID."""
    conn = _get_conn()
    try:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute("""
                SELECT * FROM public.backtests WHERE id = %s
            """, (backtest_id,))
            
            row = cur.fetchone()
            return dict(row) if row else None
    finally:
        _put_conn(conn)


def fetch_backtest_signals(backtest_id: int) -> List[Dict[str, Any]]:
    """Fetch all signals for a specific backtest."""
    conn = _get_conn()
    try:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute("""
                SELECT * FROM public.backtest_signals 
                WHERE backtest_id = %s 
                ORDER BY signal_time
            """, (backtest_id,))
            
            rows = cur.fetchall()
            return [dict(row) for row in rows]
    finally:
        _put_conn(conn)


def fetch_all_backtests(symbol: Optional[str] = None, 
                       limit: int = 50) -> List[Dict[str, Any]]:
    """Fetch all backtests with optional filtering."""
    conn = _get_conn()
    try:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            base_query = """
                SELECT b.*, 
                       COUNT(bs.id) as total_signals,
                       COUNT(CASE WHEN bs.result = 'profit' THEN 1 END) as win_count,
                       COUNT(CASE WHEN bs.result = 'loss' THEN 1 END) as loss_count,
                       COUNT(CASE WHEN bs.result = 'open' THEN 1 END) as open_count
                FROM public.backtests b
                LEFT JOIN public.backtest_signals bs ON b.id = bs.backtest_id
            """
            
            params = []
            if symbol:
                base_query += " WHERE b.symbol = %s"
                params.append(symbol)
            
            base_query += """
                GROUP BY b.id
                ORDER BY b.created_at DESC
                LIMIT %s
            """
            params.append(limit)
            
            cur.execute(base_query, params)
            rows = cur.fetchall()
            return [dict(row) for row in rows]
    finally:
        _put_conn(conn)


def insert_backtest_summary(strategy_id: int, symbol: str, timeframe: str,
                           start_date: datetime, end_date: datetime,
                           investment: float, total_return_pct: float,
                           efficiency_pct: float) -> int:
    """Insert backtest summary and return the backtest ID."""
    conn = _get_conn()
    try:
        with conn.cursor() as cur:
            cur.execute("""
                INSERT INTO public.backtests 
                (strategy_id, symbol, timeframe, start_date, end_date, 
                 investment, total_return_pct, efficiency_pct, created_at)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                RETURNING id
            """, (
                strategy_id, symbol, timeframe, start_date, end_date,
                investment, total_return_pct, efficiency_pct, datetime.now()
            ))
            
            backtest_id = cur.fetchone()[0]
            conn.commit()
            return backtest_id
    finally:
        _put_conn(conn)


def insert_backtest_signals_batch(backtest_id: int, signals: List[Dict[str, Any]]) -> None:
    """Insert multiple backtest signals in batch."""
    if not signals:
        return
        
    conn = _get_conn()
    try:
        with conn.cursor() as cur:
            # Prepare batch insert
            insert_query = """
                INSERT INTO public.backtest_signals 
                (backtest_id, signal_time, direction, entry_price, exit_price, 
                 profit_pct, result, confidence, reason)
                VALUES %s
            """
            
            # Prepare values for batch insert
            values = []
            for signal in signals:
                values.append((
                    backtest_id,
                    signal.get('signal_time'),
                    signal.get('direction'),
                    signal.get('entry_price'),
                    signal.get('exit_price'),
                    signal.get('profit_pct'),
                    signal.get('result'),
                    signal.get('confidence'),
                    signal.get('reason')
                ))
            
            # Use execute_values for efficient batch insert
            from psycopg2.extras import execute_values
            execute_values(cur, insert_query, values)
            conn.commit()
    finally:
        _put_conn(conn)


def fetch_recent_signals_by_symbol(symbol: str, limit: int = 5) -> List[Dict[str, Any]]:
    """Return the most recent signals for a given symbol with timeout protection."""
    conn = _get_conn()
    try:
        with conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                # Set statement timeout for this query
                cur.execute("SET statement_timeout = '15s'")
                
                cur.execute(
                    "select * from public.signals where symbol = %s order by timestamp desc limit %s",
                    (symbol, limit),
                )
                rows = cur.fetchall()
                return [dict(row) for row in rows]
    except psycopg2.OperationalError as e:
        raise RuntimeError(f"Database operational error fetching recent signals: {e}")
    except Exception as e:
        raise RuntimeError(f"Unexpected error fetching recent signals: {e}")
    finally:
        _put_conn(conn)


def fetch_latest_signal_by_symbol(symbol: str) -> Optional[Dict[str, Any]]:
    """Return the latest signal row for a given symbol, or None, with timeout protection."""
    conn = _get_conn()
    try:
        with conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                # Set statement timeout for this query
                cur.execute("SET statement_timeout = '10s'")
                
                cur.execute(
                    "select * from public.signals where symbol = %s order by timestamp desc limit 1",
                    (symbol,),
                )
                row = cur.fetchone()
                return dict(row) if row else None
    except psycopg2.OperationalError as e:
        raise RuntimeError(f"Database operational error fetching latest signal: {e}")
    except Exception as e:
        raise RuntimeError(f"Unexpected error fetching latest signal: {e}")
    finally:
        _put_conn(conn)


# Legacy backtesting functions removed - use unified BacktestEngine functions instead


def ensure_signal_evaluation_tables() -> None:
    """Create signal evaluation tables if they don't exist."""
    conn = _get_conn()
    try:
        with conn:
            with conn.cursor() as cur:
                # Create signal_results table
                cur.execute("""
                    CREATE TABLE IF NOT EXISTS public.signal_results (
                        id SERIAL PRIMARY KEY,
                        signal_id BIGINT NOT NULL REFERENCES public.signals(id),
                        result TEXT NOT NULL CHECK (result IN ('profit', 'loss', 'open')),
                        exit_price FLOAT,
                        profit_pct FLOAT,
                        evaluated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                        evaluation_notes TEXT,
                        UNIQUE(signal_id)
                    );
                """)
                
                # Create signal_performance_summary table
                cur.execute("""
                    CREATE TABLE IF NOT EXISTS public.signal_performance_summary (
                        id SERIAL PRIMARY KEY,
                        strategy_id INT,
                        symbol TEXT NOT NULL,
                        timeframe TEXT NOT NULL,
                        total_signals INT DEFAULT 0,
                        win_count INT DEFAULT 0,
                        loss_count INT DEFAULT 0,
                        open_count INT DEFAULT 0,
                        avg_profit_pct FLOAT DEFAULT 0.0,
                        total_roi_pct FLOAT DEFAULT 0.0,
                        efficiency_pct FLOAT DEFAULT 0.0,
                        last_updated TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                        UNIQUE(symbol, timeframe)
                    );
                """)
                
                # Create signal_performance_daily table for analytics
                cur.execute("""
                    CREATE TABLE IF NOT EXISTS public.signal_performance_daily (
                        id SERIAL PRIMARY KEY,
                        evaluation_date DATE NOT NULL,
                        symbol TEXT NOT NULL,
                        timeframe TEXT NOT NULL,
                        signals_evaluated INT DEFAULT 0,
                        new_profits INT DEFAULT 0,
                        new_losses INT DEFAULT 0,
                        daily_roi_pct FLOAT DEFAULT 0.0,
                        created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                        UNIQUE(evaluation_date, symbol, timeframe)
                    );
                """)
    finally:
        _put_conn(conn)


def fetch_signals_by_date(target_date) -> List[Dict[str, Any]]:
    """Fetch all signals from a specific date."""
    conn = _get_conn()
    try:
        with conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                cur.execute("""
                    SELECT * FROM public.signals 
                    WHERE DATE(timestamp) = %s
                    ORDER BY timestamp ASC
                """, (target_date.date(),))
                rows = cur.fetchall()
                return [dict(row) for row in rows]
    finally:
        _put_conn(conn)


def fetch_open_signals() -> List[Dict[str, Any]]:
    """Fetch all signals that are still marked as 'open'."""
    conn = _get_conn()
    try:
        with conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                cur.execute("""
                    SELECT s.*, sr.result, sr.evaluated_at
                    FROM public.signals s
                    LEFT JOIN public.signal_results sr ON s.id = sr.signal_id
                    WHERE sr.result = 'open' OR sr.result IS NULL
                    ORDER BY s.timestamp ASC
                """)
                rows = cur.fetchall()
                return [dict(row) for row in rows]
    finally:
        _put_conn(conn)


def fetch_signal_performance_summary(symbol: str = None, timeframe: str = None) -> List[Dict[str, Any]]:
    """Fetch signal performance summary statistics."""
    conn = _get_conn()
    try:
        with conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                base_query = """
                    SELECT * FROM public.signal_performance_summary
                """
                params = []
                conditions = []
                
                if symbol:
                    conditions.append("symbol = %s")
                    params.append(symbol)
                
                if timeframe:
                    conditions.append("timeframe = %s")
                    params.append(timeframe)
                
                if conditions:
                    base_query += " WHERE " + " AND ".join(conditions)
                
                base_query += " ORDER BY symbol, timeframe"
                
                cur.execute(base_query, params)
                rows = cur.fetchall()
                return [dict(row) for row in rows]
    finally:
        _put_conn(conn)


def check_database_health() -> Dict[str, Any]:
    """Check database connectivity and basic performance metrics."""
    import time
    
    health_status = {
        "status": "unknown",
        "connection_time_ms": None,
        "query_time_ms": None,
        "pool_available": False,
        "error": None
    }
    
    start_time = time.time()
    
    try:
        # Test connection acquisition
        conn = _get_conn()
        connection_time = (time.time() - start_time) * 1000
        health_status["connection_time_ms"] = round(connection_time, 2)
        health_status["pool_available"] = True
        
        # Test basic query
        query_start = time.time()
        with conn:
            with conn.cursor() as cur:
                cur.execute("SET statement_timeout = '5s'")
                cur.execute("SELECT 1 as health_check")
                result = cur.fetchone()
                
        query_time = (time.time() - query_start) * 1000
        health_status["query_time_ms"] = round(query_time, 2)
        
        if result and result[0] == 1:
            health_status["status"] = "healthy"
        else:
            health_status["status"] = "unhealthy"
            health_status["error"] = "Unexpected query result"
            
    except Exception as e:
        health_status["status"] = "unhealthy"
        health_status["error"] = str(e)
    finally:
        try:
            _put_conn(conn)
        except:
            pass  # Don't mask original error
    
    return health_status